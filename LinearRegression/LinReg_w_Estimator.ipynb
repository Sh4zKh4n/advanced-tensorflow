{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have version 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "print(\"You have version %s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For fast (data) visualization \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# as a sanity check, let's use Pandas and numpy \n",
    "# as the previous method of data pipelining  \n",
    "import pandas\n",
    "import pandas as pd  \n",
    "import numpy \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mobicfd/ReacCFD/advanced-tensorflow/LinearRegression\n",
      "['LinReg_w_Estimator.ipynb', 'LinearRegression.ipynb', '.ipynb_checkpoints', 'graphs', 'LinReg_ex1data1']\n"
     ]
    }
   ],
   "source": [
    "# Using Python (native, built-in) libraries os, sys \n",
    "# is a great way to check if we have the files we need in our \n",
    "# local file directories\n",
    "import os, sys\n",
    "print(os.getcwd()) # get the current, local file directory\n",
    "print(os.listdir(os.getcwd() )) # list the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "print(os.sep)\n",
    "PATH = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The CSV features in our training & test data\n",
    "feature_names = ['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def from_txt_to_ds_input_fn(file_path, m_i, feature_names, \n",
    "                            repeat_count=None, perform_shuffle=False, \n",
    "                               shuffle_buffer_size=4096):\n",
    "    \"\"\"\n",
    "    @fn from_txt_to_ds_input_fn\n",
    "    @param file_path\n",
    "    @param m_i, a positive integer, number of examples in a batch\n",
    "    @param feature_names, list of strings to name your d features \n",
    "    @param repeat_count, a positive integer or None, number of times to repeat, \n",
    "                None is for indefinitely\n",
    "    @param perform_shuffle = False , performs shuffling of data or not \n",
    "    @param shuffle_buffer_size = 4096, a positive integer\n",
    "    \"\"\"\n",
    "        \n",
    "    def decode_txt(line):\n",
    "        parsed_line = tf.decode_csv(line, record_defaults=[[0.],[0.,]],\n",
    "                                        field_delim=',')\n",
    "        label = parsed_line[-1:] # Last element is the label\n",
    "        del parsed_line[-1] # Delete last element\n",
    "        features = parsed_line # Everything but last elements are the features \n",
    "\n",
    "        # X_i, y_i, only the last value in a line is the output value, y\n",
    "        # prior values, associated with a \"feature_name\", are input values  \n",
    "        d = dict(zip(feature_names, features)), label  \n",
    "        return d  \n",
    "    \n",
    "    dataset = (tf.data.TextLineDataset(file_path) # Read text file \n",
    "                .map(decode_txt, num_parallel_calls=m_i) # Transform each elem by applying decode_csv fn\n",
    "                .batch(m_i) # Batch size to use\n",
    "              )\n",
    "    if repeat_count is None:\n",
    "        dataset = dataset.repeat() # repeat indefinitely\n",
    "    else:\n",
    "        dataset = dataset.repeat(repeat_count) # Repeats dataset this # times \n",
    "\n",
    "    if perform_shuffle:\n",
    "        # Randomizes input using a window of shuffle_buffer_size elements (read into memory)\n",
    "        dataset = dataset.shuffle(buffer_size=shuffle_buffer_size)\n",
    "    \n",
    "    # create iterator\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "#    iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "    # Separate the input X data from the output y data\n",
    "    batch_features, batch_labels= iterator.get_next() \n",
    "\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "LinRegClassPATH = PATH + os.sep + 'LinReg_ex1data1'\n",
    "if not os.path.exists(LinRegClassPATH):\n",
    "    os.makedirs(LinRegClassPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ex1data2.txt', 'ex1data1.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DATASET = \"../sample_datasets/\"\n",
    "os.listdir( PATH_DATASET )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FILE_ex1data1 = PATH_DATASET + os.sep + \"ex1data1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create the feature_columns, which specifies the input to our model\n",
    "# All our input features are numeric, so use numeric_column for each one \n",
    "feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# `tf.estimator.LinearRegressor`  \n",
    "\n",
    "`__init__`  \n",
    "\n",
    "```  \n",
    "__init__(\n",
    "    feature_columns,\n",
    "    model_dir=None,\n",
    "    label_dimension=1,\n",
    "    weight_column=None,\n",
    "    optimizer='Ftrl',\n",
    "    config=None,\n",
    "    partitioner=None\n",
    "    )\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7bbfa12450>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './LinReg_ex1data1', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "LinReg = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns, # The input features to our model\n",
    "    model_dir=LinRegClassPATH) # Path to where checkpoints etc. are stored  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./LinReg_ex1data1/model.ckpt-3000\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into ./LinReg_ex1data1/model.ckpt.\n",
      "INFO:tensorflow:loss = 868.532, step = 3001\n",
      "INFO:tensorflow:global_step/sec: 516.539\n",
      "INFO:tensorflow:loss = 868.532, step = 3101 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 576.126\n",
      "INFO:tensorflow:loss = 868.532, step = 3201 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.217\n",
      "INFO:tensorflow:loss = 868.532, step = 3301 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.564\n",
      "INFO:tensorflow:loss = 868.532, step = 3401 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.566\n",
      "INFO:tensorflow:loss = 868.532, step = 3501 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.868\n",
      "INFO:tensorflow:loss = 868.532, step = 3601 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.592\n",
      "INFO:tensorflow:loss = 868.532, step = 3701 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.393\n",
      "INFO:tensorflow:loss = 868.532, step = 3801 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.117\n",
      "INFO:tensorflow:loss = 868.532, step = 3901 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 587.048\n",
      "INFO:tensorflow:loss = 868.532, step = 4001 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.18\n",
      "INFO:tensorflow:loss = 868.532, step = 4101 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.833\n",
      "INFO:tensorflow:loss = 868.532, step = 4201 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.935\n",
      "INFO:tensorflow:loss = 868.532, step = 4301 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.499\n",
      "INFO:tensorflow:loss = 868.532, step = 4401 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 798.365\n",
      "INFO:tensorflow:loss = 868.532, step = 4501 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 802.613\n",
      "INFO:tensorflow:loss = 868.532, step = 4601 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 844.602\n",
      "INFO:tensorflow:loss = 868.532, step = 4701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.686\n",
      "INFO:tensorflow:loss = 868.532, step = 4801 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 964.784\n",
      "INFO:tensorflow:loss = 868.532, step = 4901 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 980.998\n",
      "INFO:tensorflow:loss = 868.532, step = 5001 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 992.892\n",
      "INFO:tensorflow:loss = 868.532, step = 5101 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 1013.82\n",
      "INFO:tensorflow:loss = 868.532, step = 5201 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 898.344\n",
      "INFO:tensorflow:loss = 868.532, step = 5301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.468\n",
      "INFO:tensorflow:loss = 868.532, step = 5401 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.053\n",
      "INFO:tensorflow:loss = 868.532, step = 5501 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 883.892\n",
      "INFO:tensorflow:loss = 868.532, step = 5601 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 830.207\n",
      "INFO:tensorflow:loss = 868.532, step = 5701 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 751.727\n",
      "INFO:tensorflow:loss = 868.532, step = 5801 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 822.672\n",
      "INFO:tensorflow:loss = 868.532, step = 5901 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 736.069\n",
      "INFO:tensorflow:loss = 868.532, step = 6001 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 851.955\n",
      "INFO:tensorflow:loss = 868.532, step = 6101 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.04\n",
      "INFO:tensorflow:loss = 868.532, step = 6201 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 858.776\n",
      "INFO:tensorflow:loss = 868.532, step = 6301 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.094\n",
      "INFO:tensorflow:loss = 868.532, step = 6401 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1015.9\n",
      "INFO:tensorflow:loss = 868.532, step = 6501 (0.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 1064.24\n",
      "INFO:tensorflow:loss = 868.532, step = 6601 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 896.861\n",
      "INFO:tensorflow:loss = 868.532, step = 6701 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 1012.37\n",
      "INFO:tensorflow:loss = 868.532, step = 6801 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.454\n",
      "INFO:tensorflow:loss = 868.532, step = 6901 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 914.736\n",
      "INFO:tensorflow:loss = 868.532, step = 7001 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 1030.22\n",
      "INFO:tensorflow:loss = 868.532, step = 7101 (0.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.934\n",
      "INFO:tensorflow:loss = 868.532, step = 7201 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.92\n",
      "INFO:tensorflow:loss = 868.532, step = 7301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 742.858\n",
      "INFO:tensorflow:loss = 868.532, step = 7401 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 861.765\n",
      "INFO:tensorflow:loss = 868.532, step = 7501 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.706\n",
      "INFO:tensorflow:loss = 868.532, step = 7601 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 780.774\n",
      "INFO:tensorflow:loss = 868.532, step = 7701 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 830.647\n",
      "INFO:tensorflow:loss = 868.532, step = 7801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 937.392\n",
      "INFO:tensorflow:loss = 868.532, step = 7901 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 931.602\n",
      "INFO:tensorflow:loss = 868.532, step = 8001 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 933.202\n",
      "INFO:tensorflow:loss = 868.532, step = 8101 (0.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 957.588\n",
      "INFO:tensorflow:loss = 868.532, step = 8201 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 1139.04\n",
      "INFO:tensorflow:loss = 868.532, step = 8301 (0.089 sec)\n",
      "INFO:tensorflow:global_step/sec: 1107.21\n",
      "INFO:tensorflow:loss = 868.532, step = 8401 (0.090 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8500 into ./LinReg_ex1data1/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 868.532.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f7bbfa12990>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinReg.train(\n",
    "    input_fn=lambda: from_txt_to_ds_input_fn(FILE_ex1data1,\n",
    "                                                128, \n",
    "                                                feature_names,\n",
    "                                                 5500, \n",
    "                                             True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['global_step',\n",
       " 'linear/linear_model/X/weights',\n",
       " 'linear/linear_model/X/weights/part_0/Ftrl',\n",
       " 'linear/linear_model/X/weights/part_0/Ftrl_1',\n",
       " 'linear/linear_model/bias_weights',\n",
       " 'linear/linear_model/bias_weights/part_0/Ftrl',\n",
       " 'linear/linear_model/bias_weights/part_0/Ftrl_1']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinReg.get_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinReg.get_variable_value('global_step' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.19302714]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinReg.get_variable_value('linear/linear_model/X/weights' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.8957181], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinReg.get_variable_value( 'linear/linear_model/bias_weights' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case of multi-variate linear regression with a `.txt` file with no header, `ex1data2.txt`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The CSV features in our training & test data\n",
    "feature_names = ['X1','X2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FILE_ex1data2 = PATH_DATASET + os.sep + \"ex1data2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LinRegClassPATH = PATH + os.sep + 'LinReg_ex1data2'\n",
    "if not os.path.exists(LinRegClassPATH):\n",
    "    os.makedirs(LinRegClassPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(k) for k in feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7baa459090>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': './LinReg_ex1data2', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "LinReg_multi = tf.estimator.LinearRegressor(\n",
    "    feature_columns=feature_columns, # The input features to our model\n",
    "    model_dir=LinRegClassPATH) # Path to where checkpoints etc. are stored  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature X2 is not in features dictionary.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-3e5f7c6801aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m LinReg_multi.train(\n\u001b[0;32m----> 2\u001b[0;31m     input_fn=lambda: from_txt_to_ds_input_fn(FILE_ex1data2,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                 \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                 \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                  \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/canned/linear.pyc\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    346\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    349\u001b[0m     super(LinearRegressor, self).__init__(\n\u001b[1;32m    350\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/canned/linear.pyc\u001b[0m in \u001b[0;36m_linear_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, optimizer, partitioner, config)\u001b[0m\n\u001b[1;32m    116\u001b[0m     logit_fn = _linear_logit_fn_builder(\n\u001b[1;32m    117\u001b[0m         units=head.logits_dimension, feature_columns=feature_columns)\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train_op_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/canned/linear.pyc\u001b[0m in \u001b[0;36mlinear_logit_fn\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \"\"\"\n\u001b[1;32m     69\u001b[0m     return feature_column_lib.linear_model(\n\u001b[0;32m---> 70\u001b[0;31m         features=features, feature_columns=feature_columns, units=units)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlinear_logit_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36mlinear_model\u001b[0;34m(features, feature_columns, units, sparse_combiner, weight_collections, trainable)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m           weighted_sums.append(_create_dense_column_weighted_sum(\n\u001b[0;32m--> 321\u001b[0;31m               column, builder, units, weight_collections, trainable))\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0m_verify_static_batch_size_equality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_sums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     predictions_no_bias = math_ops.add_n(\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36m_create_dense_column_weighted_sum\u001b[0;34m(column, builder, units, weight_collections, trainable)\u001b[0m\n\u001b[1;32m   1364\u001b[0m       \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m       \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1366\u001b[0;31m       trainable=trainable)\n\u001b[0m\u001b[1;32m   1367\u001b[0m   \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1731\u001b[0m     \u001b[0;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m     \u001b[0;31m# representation created by _transform_feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforming feature_column %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Column {} is not supported.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36m_transform_feature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1700\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1701\u001b[0;31m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1702\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/feature_column/feature_column.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_FeatureColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Feature {} is not in features dictionary.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature X2 is not in features dictionary."
     ]
    }
   ],
   "source": [
    "LinReg_multi.train(\n",
    "    input_fn=lambda: from_txt_to_ds_input_fn(FILE_ex1data2,\n",
    "                                                128, \n",
    "                                                feature_names,\n",
    "                                                 500, \n",
    "                                             True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='X1', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='X2', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
