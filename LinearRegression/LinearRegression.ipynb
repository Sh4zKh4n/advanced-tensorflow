{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I quote heavily from the official TensorFlow website, namely their Programmers' Guide for [Importing Data](https://www.tensorflow.org/programmers_guide/datasets), and copy what's there verbatim (since it's the official API guide), largely for convenience (I don't have a wifi connection all the time, even like for people in rural USA, and so how can you access the official programmers' guide offline?), while adding my notes on top of it.  So feel free to copy, edit, paste as you'd like too.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have version 1.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "print(\"You have version %s\" % tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For fast (data) visualization \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# as a sanity check, let's use Pandas and numpy \n",
    "# as the previous method of data pipelining  \n",
    "import pandas\n",
    "import pandas as pd  \n",
    "import numpy \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mobicfd/ReacCFD/advanced-tensorflow/LinearRegression\n",
      "['LinearRegression.ipynb', '.ipynb_checkpoints', 'graphs']\n"
     ]
    }
   ],
   "source": [
    "# Using Python (native, built-in) libraries os, sys \n",
    "# is a great way to check if we have the files we need in our \n",
    "# local file directories\n",
    "import os, sys\n",
    "print(os.getcwd()) # get the current, local file directory\n",
    "print(os.listdir(os.getcwd() )) # list the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sample `.txt` data  \n",
    "#### cf. Coursera, *Introduction to Machine Learning* by Prof. Ng  \n",
    "Join the free class, download the homework and they're in the files `machine-learning-ex1.zip`, `machine-learning-ex2.zip` and in the folders `ex1/ex1data1.txt`, `ex2/ex1data2/txt`, respectively, and save them locally here.  \n",
    "\n",
    "`ex1data1.txt` is a simple case, where the data is clean, there's no header, and \n",
    "\n",
    "input data $X \\in \\text{Mat}_{\\mathbb{R}}(m,d)$, with $m$ being the number of examples given (97 in this case) and there are only $d=1$ features of our input data, and \n",
    "\n",
    "the output data, on the \"right-most column\", is $y\\in \\text{Mat}_{\\mathbb{R}}(m,K)$, with $K$ being the dimension of the output ($K=1$ in this case).  \n",
    "\n",
    "Note that we want to find a linear relationship from $X_i \\in \\mathbb{R}$ to $y_i \\in \\mathbb{R}$, i.e.  \n",
    "\n",
    "$$ \n",
    "    X_i \\mapsto y_i  \n",
    "$$ \n",
    "\n",
    "$\\forall \\, i \\in 0,1,\\dots m-1$.  \n",
    "\n",
    "As a note on notation, $\\mathbb{R}$ stands for the set of all real numbers, and for computers they correspond to float or double types.  For GPUs, we work with 32-bit floating-point numbers (this is because of the hardware architecture of GPUs).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_datasets_subdir_str = \"sample_datasets/\"\n",
    "sample_datasets_basedir_str = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1data2.txt\n",
      "ex1data1.txt\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(sample_datasets_basedir_str + sample_datasets_subdir_str):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        print filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sample_datasets_fileloc_str = sample_datasets_basedir_str + sample_datasets_subdir_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# `.txt` $\\to$  `tf.data.Dataset`  \n",
    "\n",
    "`TextLineDataset`, a class inheriting from the `Datasets` base class *reads lines from text files*.  By default, it'll read *every* line of each file.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.readers.TextLineDataset'>\n"
     ]
    }
   ],
   "source": [
    "ex1data1_Dataset = tf.data.TextLineDataset( sample_datasets_fileloc_str + \"/ex1data1.txt\")\n",
    "print(type(ex1data1_Dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Dataset structure (check)  \n",
    "\n",
    "Let's take a look at the dataset structure when we do `tf.data.TextLineDataset` (i.e. `.txt` $\\to$ `tf.data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'string'>\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "print(ex1data1_Dataset.output_types)  \n",
    "print(ex1data1_Dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The datasets comprises of elements each of the same structure (or type).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now write a Python function to parse this string; for [`tf.decode_csv`](https://www.tensorflow.org/api_docs/python/tf/decode_csv), the API (i.e. the input parameters to use),  \n",
    "```  \n",
    "decode_csv(records,record_defaults,field_delim=',',use_quote_delim=True,name=None,na_value='') \n",
    "```  \n",
    "`records` is a `Tensor` of type `string` (which we have in thise case) and each string is a record/row in the `csv` and all the \"records\" is assumed to have the same format (for our `.txt` file).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def decode_func_txt(line):\n",
    "    record_defaults =[[0.0],[0.0]]\n",
    "    line = tf.decode_csv(line, record_defaults=record_defaults, field_delim=',')\n",
    "    return line[:-1], line[-1] # X_i, y_i, only the last value in a line \n",
    "                            # is the output value, the prior values are input values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[`.batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), `.batch(batch_size)`, combines consecutive elements of a dataset into batches, and `batch_size` is a `tf.int64` scalar `tf.Tensor` (i.e. a positive integer $\\in \\mathbb{Z}^+$, representing the number of consecutive elements of this dataset to combine in a single batch.   \n",
    "\n",
    "Let $m_i = $ size of a single batch $ \\in \\mathbb{Z}^+$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# m_i = size of a single batch  \n",
    "m_i = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "ex1data1_Dataset = ex1data1_Dataset.batch(m_i)\n",
    "print(type(ex1data1_Dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[`.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), `.map(map_func, num_parallel_calls=None)` maps the `map_func` (e.g. a Python function) across the dataset, where `map_func` is a \"function mapping a nested structure of tensors (having shapes and types defined by `self.output_shapes` and `self.output_types`) to another nested structure of tensors, and  \n",
    "\n",
    "`num_parallel_calls` is a `tf.int32` scalar `tf.Tensor` (i.e. it's a positive integer $\\in \\mathbb{Z}^+$) representing the number of elements to process in parallel (on a GPU(s)!).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex1data1_Dataset = ex1data1_Dataset.map(decode_func_txt, num_parallel_calls=m_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ParallelMapDataset shapes: ((1, ?), (?,)), types: (tf.float32, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "print(ex1data1_Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "[`.shuffle`](https://www.tensorflow.org/programmers_guide/datasets#randomly_shuffling_input_data) randomly shuffles the input dataset using a similar algorithm to `tf.RandomShuffleQueue`.  It maintains a fixed-size buffer, which is a positive integer $\\in \\mathbb{Z}^+$ (that you must input), and out of that buffer, chooses the next element uniformly at random from the buffer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Uncomment out when we want to do the shuffling; \n",
    "# later, we want to check if our data is the same as if we had used Pandas+NumPy\n",
    "#shuffle_buffer_size = 10000\n",
    "#ex1data1_Dataset.shuffle(shuffle_buffer_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So to recapitulate, once you've gotten  \n",
    "$$   \n",
    "    \\verb|.txt| \\xrightarrow{ tf.data.TextLineDataset } \\verb|<string>|\n",
    "$$    \n",
    "i.e. turned a text file into a string with `tf.data.TextLineDataset`, apply these 3 transformations:  \n",
    "\n",
    "- `.batch`\n",
    "- `.map` (remember to define what function you'd want to do on each line or \"record\" to process your `.txt` file; I'll try to provide examples of writing this function in these jupyter notebooks)\n",
    "- `.shuffle`  \n",
    "\n",
    "There are of course other transformations you can do to get your data ready: \n",
    "- `.filter` - write a function to process each line or \"record\" and you can do things like filter out empty lines \n",
    "- `.repeat` - repeat indefinitely  \n",
    "\n",
    "[`.repeat`](https://www.tensorflow.org/programmers_guide/datasets#training_workflows) is going to be important for when training your data.  The Programmers' guide describes it as \"process multiple epochs of the same data,\" \"to iterate over a dataset in multiple epochs\".  I believe it means this: for example, let's say we want to do gradient descent to train our model, i.e. find the global minimum to minimize cost function(al) $J$, for our \"weight\" or parameter $\\Theta$.  At iteration $t$, to obtain the next iteration $t+1$, \n",
    "\n",
    "$$   \n",
    "\\Theta(t+1) := \\Theta(t) - \\alpha \\frac{ \\partial J}{ \\partial \\Theta}(\\Theta(t))  \n",
    "$$  \n",
    "\n",
    "and \"epoch\" is synonymous to iteration, here.  \n",
    "\n",
    "So we'll go ahead and do `.repeat()` (repeat indefinitely).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'>\n"
     ]
    }
   ],
   "source": [
    "ex1data1_Dataset.repeat(1)\n",
    "print(type(ex1data1_Dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Apparently, then you have to make an initializer.  There seems to be 2 ways,  \n",
    "\n",
    "- [`.make_initializable_iterator()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), which creates an `Iterator` for enumerating the elements of this, the given, dataset; *note* the returned iterator will be in an uninitialized state, and `iterator.initializer` must be run before using it. cf. [Processing multiple epochs](https://www.tensorflow.org/programmers_guide/datasets#training_workflows)  \n",
    "- [`.make_one_shot_iterator()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), was recommended by the Datasets API documentation for high-level APIs, such as `tf.estimator.Estimator` because apparently, you need to use `tf.errors.OutOfRangeError` to signal that training has completed.  cf. [Processing multiple epochs](https://www.tensorflow.org/programmers_guide/datasets#training_workflows)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.iterator_ops.Iterator'>\n"
     ]
    }
   ],
   "source": [
    "ex1data1_iterator = ex1data1_Dataset.make_initializable_iterator()\n",
    "print(type(ex1data1_iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We still haven't split up our data $(X,y)$ into seperate Python objects for $X$ and $y$.  `.get_next()` seems to do it.  The API guide says this:  \n",
    "\n",
    "[`.get_next`](https://www.tensorflow.org/api_docs/python/tf/data/Iterator) - `.get_next(name=None` - returns a nested structure of `tf.Tensor`s containing the next element.  So I assume (read into it) that it'll give the next \"batch\" and since it's a batch of $(X,y)$ we can split up $(X,y)$ in the following manner:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "X_ex1data1_next, y_ex1data1_next = ex1data1_iterator.get_next()\n",
    "print(type(X_ex1data1_next))\n",
    "print(type(y_ex1data1_next))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'float32'>\n",
      "<dtype: 'float32'>\n",
      "(1, ?)\n",
      "(?,)\n",
      "(1, ?)\n",
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "# many interesting properties to look up\n",
    "print(X_ex1data1_next.dtype)\n",
    "print(y_ex1data1_next.dtype)\n",
    "print(X_ex1data1_next.shape)\n",
    "print(y_ex1data1_next.shape)\n",
    "print(X_ex1data1_next.get_shape() )\n",
    "print( y_ex1data1_next.get_shape() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sanity check that we've loaded the data, sanity check with how we could've done the same with Pandas + NumPy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(ex1data1_iterator.initializer)\n",
    "    ex1data1_loaded_batch_X = sess.run(X_ex1data1_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.11009979,   5.52769995,   8.51860046,   7.00320005,\n",
       "          5.85979986,   8.38290024,   7.4763999 ,   8.5781002 ,\n",
       "          6.48619986,   5.05459976,   5.71070004,  14.16399956,\n",
       "          5.73400021,   8.40839958,   5.64069986,   5.37939978,\n",
       "          6.36539984,   5.13009977,   6.42959976,   7.07079983,\n",
       "          6.18909979,  20.27000046,   5.49009991,   6.32609987,\n",
       "          5.56489992,  18.94499969,  12.82800007,  10.95699978,\n",
       "         13.17599964,  22.20299911,   5.25239992,   6.58939981,\n",
       "          9.24820042,   5.89179993,   8.21109962,   7.93340015,\n",
       "          8.09589958,   5.60629988,  12.83600044,   6.35340023,\n",
       "          5.40689993,   6.88250017,  11.70800018,   5.77370024,\n",
       "          7.82469988,   7.09310007,   5.07019997,   5.80140018,\n",
       "         11.69999981,   5.54160023,   7.54020023,   5.30770016,\n",
       "          7.42390013,   7.60309982,   6.33279991,   6.35890007,\n",
       "          6.27419996,   5.63969994,   9.31019974,   9.45359993,\n",
       "          8.82540035,   5.17929983,  21.27899933,  14.90799999]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1data1_loaded_batch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(1, 64)\n"
     ]
    }
   ],
   "source": [
    "print(type(ex1data1_loaded_batch_X))\n",
    "print(ex1data1_loaded_batch_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Indeed, this does the same as what one might have done with Pandas + NumPy:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex1data1DF = pd.read_csv(sample_datasets_fileloc_str + \"/ex1data1.txt\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97,)\n",
      "(97,)\n",
      "(97, 1)\n",
      "(97, 1)\n"
     ]
    }
   ],
   "source": [
    "Xyex1data1 = ex1data1DF.values\n",
    "Xex1data1 = Xyex1data1[:,0]\n",
    "yex1data1 = Xyex1data1[:,1]\n",
    "print(Xex1data1.shape)\n",
    "print(yex1data1.shape)\n",
    "Xex1data1 = np.vstack(Xex1data1).astype(np.float32)\n",
    "yex1data1 = np.vstack(yex1data1).astype(np.float32)\n",
    "print(Xex1data1.shape)\n",
    "print(yex1data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]], dtype=bool)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xex1data1[:64].T == ex1data1_loaded_batch_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we got all True's above, successful sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# start again\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "To recapitulate, let's wrap all the Python class member function instantiations into Python functions:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write a function to decode a line from the text file \n",
    "def decode_func_txt(line):\n",
    "    record_defaults =[[0.0],[0.0]]\n",
    "    line = tf.decode_csv(line, record_defaults=record_defaults, field_delim=',')\n",
    "    return line[:-1], line[-1] # X_i, y_i, only the last value in a line \n",
    "                            # is the output value, the prior values are input values  \n",
    "\n",
    "def create_1dimXydataset_fn(path,m_i,num_repeats=None,bool_shuffle=True,\n",
    "                            shuffle_buffer_size=10000):\n",
    "    \"\"\"\n",
    "    @fn create_1dimXydataset_fun\n",
    "    @param path, string, a string with the filename's path\n",
    "    @param m_i, a positive integer, number of examples in a batch\n",
    "    @param num_repeats, a positive integer or None, number of times to repeat, \n",
    "                        None is for indefinitely\n",
    "    @param bool_shuffle = True \n",
    "    @param shuffle_buffer_size, a positive integer, default is 10000\n",
    "    \"\"\"\n",
    "    def input_fn():\n",
    "        dataset = (\n",
    "            tf.data.TextLineDataset(path) # create a dataset from a file \n",
    "                .map(decode_func_txt, num_parallel_calls=m_i)\n",
    "                .batch(m_i)                \n",
    "        )\n",
    "        \n",
    "        if num_repeats is None:\n",
    "            dataset=dataset.repeat() # repeat indefinitely\n",
    "        else:\n",
    "            dataset=dataset.repeat(num_repeats)\n",
    "\n",
    "        if bool_shuffle:\n",
    "            dataset=dataset.shuffle(shuffle_buffer_size)    \n",
    "            \n",
    "        # create iterator\n",
    "        iterator = dataset.make_initializable_iterator()  \n",
    "        \n",
    "        # separate the input X data from the output y data\n",
    "        X_next, y_next = iterator.get_next()\n",
    "\n",
    "        # we'll need to return the iterator as well to initialize it at tf.Session time\n",
    "        return (X_next, y_next), iterator \n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# let's test out our function\n",
    "ex1data1_fn = create_1dimXydataset_fn(sample_datasets_fileloc_str + \"/ex1data1.txt\", \n",
    "                                      m_i, 1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "(ex1data1_X_next, ex1data1_y_next), ex1data1_iterator = ex1data1_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(ex1data1_iterator.initializer)\n",
    "    ex1data1_loaded_batch_X = sess.run(ex1data1_X_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(64, 1)\n"
     ]
    }
   ],
   "source": [
    "print( type( ex1data1_loaded_batch_X ) )\n",
    "print( ex1data1_loaded_batch_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True]], dtype=bool)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1data1_loaded_batch_X.T == Xex1data1[:64].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "What happens if $m_i$, batch size, is greater than examples we have in our data set, $m=97$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# start again\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex1data1_fn = create_1dimXydataset_fn(sample_datasets_fileloc_str + \"/ex1data1.txt\", \n",
    "                                      128, 1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex1data1_Xy_next, ex1data1_iterator = ex1data1_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(ex1data1_iterator.initializer)\n",
    "    (ex1data1_loaded_batch_X, ex1data1_loaded_batch_y) = sess.run(ex1data1_Xy_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(97, 1)\n"
     ]
    }
   ],
   "source": [
    "print( type( ex1data1_loaded_batch_X ) )\n",
    "print( ex1data1_loaded_batch_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we obtain a shape of `(97,1)`, then the iterator knew to stop.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex1data1_loaded_batch_X.T == Xex1data1.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Linear Regression Model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can use the data we've just pipelined through `tf.data` to make a plot in `matplotlib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f75a8317790>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCRI6AJQECR0ASoKEDgAlQUIHgJL4fxq7BGP6U3ggAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75ac476b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ex1data1_loaded_batch_X,ex1data1_loaded_batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The Linear Regression Model is mathematically formally the following:  \n",
    "\n",
    "$$\n",
    "    \\widehat{y} = X \\Theta + b  \n",
    "$$ \n",
    "\n",
    "where $\\widehat{y}, b \\in \\text{Mat}_{\\mathbb{R}}(m,K)$, $X \\in \\text{Mat}_{\\mathbb{R}}(m,d)$, $\\Theta \\in \\text{Mat}_{\\mathbb{R}}(d,K)$, with bias $b$ having the particular form that  \n",
    "\n",
    "$$\n",
    "    b_{ij} = b^j \\qquad \\, \\forall \\, i =0,1,\\dots m-1, \\, j=0,1,\\dots K-1\n",
    "$$  \n",
    "\n",
    "i.e. entries of $b$ only depends on which \"column\" it's in, $j$.  \n",
    "\n",
    "Usually, one only sees this function written for linear regression:\n",
    "\n",
    "$$  \n",
    "    y = mx +b  \n",
    "$$  \n",
    "because we're only thinking about applying the function to 1 number, 1 example, to get the output of just this 1 input.  \n",
    "\n",
    "But I want to point out that we want to operate on the entirety of large batches of examples; so we must consider matrices.  And usually we multiply on the left, as when we first learn matrix multiplication.   \n",
    "\n",
    "But for GPUs, you want to multiply *from the right*.  Indeed, this has been well-formulated mathematically as *right $R$-modules*.  \n",
    "\n",
    "The reason why, I suspect, is that in the source code of TensorFlow, for the `cuda` `platform` and `streaming` subdirectories, TensorFlow is wrapping, in C++, CUBLAS API calls and for CUBLAS, you want the first dimension of the matrix to be each successive dataset example, *not* the columns or $d$ features of your input data.  This is because you want *thread warp coalescing* when running computations on a GPU(s).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define our Linear Regression model in `tf`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# start again\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex1data1_fn = create_1dimXydataset_fn(sample_datasets_fileloc_str + \"/ex1data1.txt\", \n",
    "                                      64, None,True)\n",
    "ex1data1_Xy_next, ex1data1_iterator = ex1data1_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# size dimension shapes are important (and severely enforced)\n",
    "d=1\n",
    "K=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('1dimLinRegmodel'):\n",
    "#    Theta_1d = tf.Variable(tf.random_normal([d,K]), name=\"Theta_1d\")\n",
    "#    b_1d     = tf.Variable(tf.random_normal([K]), name=\"b_1d\")\n",
    "    Theta_1d = tf.Variable(tf.constant(1.0,shape=[d,K]), name=\"Theta_1d\")\n",
    "    b_1d     = tf.Variable(tf.constant(0.0,shape=[K]), name=\"b_1d\")\n",
    "    yhat = tf.matmul(ex1data1_Xy_next[0], Theta_1d) + b_1d #predicted y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('1dimLinRegmodel'):\n",
    "    Theta_1d = tf.Variable(tf.random_normal([d,K]), name=\"Theta_1d\")\n",
    "    b_1d     = tf.Variable(tf.random_normal([K]), name=\"b_1d\")\n",
    "    yhat = tf.matmul(ex1data1_Xy_next[0], Theta_1d) + b_1d #predicted y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alpha_rate = 0.005 # learning rate \n",
    "\n",
    "with tf.name_scope(\"1dLinReg_training\"):\n",
    "    # J = cost function(al)\n",
    "    with tf.name_scope('1dLinReg_J'):\n",
    "        J_1dLinReg = tf.reduce_mean(  \n",
    "                tf.square( yhat - ex1data1_Xy_next[1] )\n",
    "                    )\n",
    "    with tf.name_scope('1dLinReg_optimizer'):\n",
    "        optimizer_1dLinReg = tf.train.GradientDescentOptimizer(alpha_rate)\n",
    "        train_1dLinReg = optimizer_1dLinReg.minimize(J_1dLinReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"1dimLinRegmodel/add:0\", shape=(?, 1), dtype=float32) must be from the same graph as Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5df2807a4b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1dLinReg_J'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         J_1dLinReg = tf.reduce_mean(  \n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mex1data1_Xy_next\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                     )\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1dLinReg_optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36msquared_difference\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   4599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4600\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 4601\u001b[0;31m         \"SquaredDifference\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   4602\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4603\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   4634\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4635\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4636\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4637\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4638\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   4570\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4571\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[0;32m-> 4572\u001b[0;31m                                                                 original_item))\n\u001b[0m\u001b[1;32m   4573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"1dimLinRegmodel/add:0\", shape=(?, 1), dtype=float32) must be from the same graph as Tensor(\"IteratorGetNext:1\", shape=(?,), dtype=float32)."
     ]
    }
   ],
   "source": [
    "alpha_rate = 0.0001 # learning rate \n",
    "\n",
    "with tf.name_scope(\"1dLinReg_training\"):\n",
    "    # J = cost function(al)\n",
    "    with tf.name_scope('1dLinReg_J'):\n",
    "        J_1dLinReg = tf.reduce_mean(  \n",
    "                tf.squared_difference( yhat,  ex1data1_Xy_next[1] )\n",
    "                    )\n",
    "    with tf.name_scope('1dLinReg_optimizer'):\n",
    "        optimizer_1dLinReg = tf.train.GradientDescentOptimizer(alpha_rate)\n",
    "        train_1dLinReg = optimizer_1dLinReg.minimize(J_1dLinReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "alpha_rate = 0.0001 # learning rate \n",
    "reg_constant_lambda = 0.00001 # Choose an appropriate one\n",
    "\n",
    "\n",
    "with tf.name_scope(\"1dLinReg_training_w_reg\"):\n",
    "    # J = cost function(al)\n",
    "    with tf.name_scope('1dLinReg_J'):\n",
    "        # regularization term \n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        \n",
    "        J_1dLinReg = tf.reduce_mean( \n",
    "                        tf.square( \n",
    "                            yhat - ex1data1_Xy_next[1] \n",
    "                        )) + reg_constant_lambda * sum(reg_losses)\n",
    "    with tf.name_scope('1dLinReg_optimizer'):\n",
    "        optimizer_1dLinReg = tf.train.GradientDescentOptimizer(alpha_rate)\n",
    "        train_1dLinReg = optimizer_1dLinReg.minimize(J_1dLinReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Initialize variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.run(ex1data1_iterator.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### (optional) Set up Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This is a directory we'll use to store information\n",
    "# about the graph to later visualize in TensorBoard\n",
    "# By default, it will be created in the same directory\n",
    "# as this notebook.  \n",
    "\n",
    "# Be sure to delete the contents of this directory before\n",
    "# running the script\n",
    "LOGDIR = './graphs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write the graph\n",
    "writer = tf.summary.FileWriter(LOGDIR)\n",
    "writer.add_graph(sess.graph)  \n",
    "\n",
    "# Attach summaries to Tensors (for TensorBoard visualization)  \n",
    "#tf.summary.histogram('Theta_1d', Theta_1d)\n",
    "#tf.summary.histogram('b_1d', b_1d)\n",
    "tf.summary.scalar('lossJ', J_1dLinReg)\n",
    "\n",
    "# This op will calculate our summary data when run\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [array([[-0.78371745]], dtype=float32), array([-1.47793901], dtype=float32), 255.20645])\n",
      "(100, [array([[ 0.39789283]], dtype=float32), array([-1.33391666], dtype=float32), 56.505692])\n",
      "(200, [array([[ 0.62796229]], dtype=float32), array([-1.28718674], dtype=float32), 45.893818])\n",
      "(300, [array([[ 0.67622054]], dtype=float32), array([-1.25824821], dtype=float32), 27.927433])\n",
      "(400, [array([[ 0.68216312]], dtype=float32), array([-1.23408723], dtype=float32), 44.566032])\n",
      "(500, [array([[ 0.69005734]], dtype=float32), array([-1.20970392], dtype=float32), 28.110907])\n",
      "(600, [array([[ 0.6810438]], dtype=float32), array([-1.18712616], dtype=float32), 27.965609])\n",
      "(700, [array([[ 0.68580294]], dtype=float32), array([-1.16281998], dtype=float32), 44.211617])\n",
      "(800, [array([[ 0.68132937]], dtype=float32), array([-1.13974404], dtype=float32), 44.17363])\n",
      "(900, [array([[ 0.66610253]], dtype=float32), array([-1.11866677], dtype=float32), 44.301968])\n",
      "(1000, [array([[ 0.65582168]], dtype=float32), array([-1.09726417], dtype=float32), 44.372742])\n",
      "(1100, [array([[ 0.65773207]], dtype=float32), array([-1.07409322], dtype=float32), 44.237011])\n",
      "(1200, [array([[ 0.66501993]], dtype=float32), array([-1.05055416], dtype=float32), 44.022163])\n",
      "(1300, [array([[ 0.67629647]], dtype=float32), array([-1.02503109], dtype=float32), 43.764862])\n",
      "(1400, [array([[ 0.67038059]], dtype=float32), array([-1.00238633], dtype=float32), 43.746681])\n",
      "(1500, [array([[ 0.65747482]], dtype=float32), array([-0.98146003], dtype=float32), 43.836617])\n",
      "(1600, [array([[ 0.65795583]], dtype=float32), array([-0.95874017], dtype=float32), 43.73315])\n",
      "(1700, [array([[ 0.67173028]], dtype=float32), array([-0.93382078], dtype=float32), 27.781824])\n",
      "(1800, [array([[ 0.66497767]], dtype=float32), array([-0.91169143], dtype=float32), 43.446552])\n",
      "(1900, [array([[ 0.66061223]], dtype=float32), array([-0.88908887], dtype=float32), 43.409866])\n",
      "(2000, [array([[ 0.65289593]], dtype=float32), array([-0.86701095], dtype=float32), 27.465569])\n",
      "(2100, [array([[ 0.64807141]], dtype=float32), array([-0.84472233], dtype=float32), 27.3874])\n",
      "(2200, [array([[ 0.64160246]], dtype=float32), array([-0.82309401], dtype=float32), 27.285894])\n",
      "(2300, [array([[ 0.63492399]], dtype=float32), array([-0.802275], dtype=float32), 43.409794])\n",
      "(2400, [array([[ 0.64135271]], dtype=float32), array([-0.77989173], dtype=float32), 27.275211])\n",
      "(2500, [array([[ 0.63313365]], dtype=float32), array([-0.75846452], dtype=float32), 27.148458])\n",
      "(2600, [array([[ 0.6406641]], dtype=float32), array([-0.73531902], dtype=float32), 43.047035])\n",
      "(2700, [array([[ 0.62927759]], dtype=float32), array([-0.71478683], dtype=float32), 43.124226])\n",
      "(2800, [array([[ 0.63154352]], dtype=float32), array([-0.69253808], dtype=float32), 27.114658])\n",
      "(2900, [array([[ 0.630849]], dtype=float32), array([-0.67056513], dtype=float32), 27.102106])\n",
      "(3000, [array([[ 0.61831325]], dtype=float32), array([-0.65038025], dtype=float32), 43.020515])\n",
      "(3100, [array([[ 0.63148266]], dtype=float32), array([-0.62715399], dtype=float32), 42.733486])\n",
      "(3200, [array([[ 0.6071772]], dtype=float32), array([-0.60882282], dtype=float32), 26.751633])\n",
      "(3300, [array([[ 0.60787243]], dtype=float32), array([-0.5881182], dtype=float32), 26.754845])\n",
      "(3400, [array([[ 0.60523766]], dtype=float32), array([-0.56782693], dtype=float32), 26.714151])\n",
      "(3500, [array([[ 0.60480255]], dtype=float32), array([-0.54757559], dtype=float32), 42.798985])\n",
      "(3600, [array([[ 0.61568862]], dtype=float32), array([-0.52505654], dtype=float32), 26.85972])\n",
      "(3700, [array([[ 0.59884304]], dtype=float32), array([-0.5064348], dtype=float32), 26.613041])\n",
      "(3800, [array([[ 0.60551643]], dtype=float32), array([-0.4847945], dtype=float32), 42.523212])\n",
      "(3900, [array([[ 0.60637975]], dtype=float32), array([-0.46401697], dtype=float32), 42.424751])\n",
      "(4000, [array([[ 0.59578711]], dtype=float32), array([-0.44457805], dtype=float32), 42.507957])\n",
      "(4100, [array([[ 0.60480136]], dtype=float32), array([-0.42281803], dtype=float32), 26.690052])\n",
      "(4200, [array([[ 0.59825641]], dtype=float32), array([-0.40260932], dtype=float32), 26.589884])\n",
      "(4300, [array([[ 0.60452187]], dtype=float32), array([-0.38087291], dtype=float32), 26.688072])\n",
      "(4400, [array([[ 0.60714525]], dtype=float32), array([-0.35978237], dtype=float32), 41.999577])\n",
      "(4500, [array([[ 0.58842808]], dtype=float32), array([-0.34133565], dtype=float32), 42.193745])\n",
      "(4600, [array([[ 0.58258313]], dtype=float32), array([-0.32205364], dtype=float32), 26.357252])\n",
      "(4700, [array([[ 0.58665133]], dtype=float32), array([-0.30123875], dtype=float32), 42.056396])\n",
      "(4800, [array([[ 0.59151465]], dtype=float32), array([-0.28051171], dtype=float32), 41.900887])\n",
      "(4900, [array([[ 0.57978028]], dtype=float32), array([-0.2620441], dtype=float32), 42.002884])\n"
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS = 5000\n",
    "\n",
    "for step in range(TRAIN_STEPS):\n",
    "    \n",
    "    # Session will run 2 ops:\n",
    "    # summary_op prepares summary data we'll write to disk in a moment\n",
    "    # - train will use the optimzer to adjust our variables to reduce loss \n",
    "    _ = sess.run(train_1dLinReg)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, sess.run([Theta_1d,b_1d, J_1dLinReg]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Infinity in summary histogram for: Theta_1d\n\t [[Node: Theta_1d = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Theta_1d/tag, 1dimLinRegmodel/Theta_1d/read/_35)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'Theta_1d', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/mobicfd/ReacCFD/tf/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-7f2410fdbf37>\", line 6, in <module>\n    tf.summary.histogram('Theta_1d', Theta_1d)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 192, in histogram\n    tag=tag, values=values, name=scope)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 188, in _histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Infinity in summary histogram for: Theta_1d\n\t [[Node: Theta_1d = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Theta_1d/tag, 1dimLinRegmodel/Theta_1d/read/_35)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a949b495b839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# summary_op prepares summary data we'll write to disk in a moment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# - train will use the optimzer to adjust our variables to reduce loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msummary_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_1dLinReg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# write the summary data to disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Infinity in summary histogram for: Theta_1d\n\t [[Node: Theta_1d = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Theta_1d/tag, 1dimLinRegmodel/Theta_1d/read/_35)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op u'Theta_1d', defined at:\n  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/home/mobicfd/ReacCFD/tf/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mobicfd/.local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-7f2410fdbf37>\", line 6, in <module>\n    tf.summary.histogram('Theta_1d', Theta_1d)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/summary/summary.py\", line 192, in histogram\n    tag=tag, values=values, name=scope)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py\", line 188, in _histogram_summary\n    \"HistogramSummary\", tag=tag, values=values, name=name)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Infinity in summary histogram for: Theta_1d\n\t [[Node: Theta_1d = HistogramSummary[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Theta_1d/tag, 1dimLinRegmodel/Theta_1d/read/_35)]]\n\t [[Node: IteratorGetNext/_25 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_IteratorGetNext\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_STEPS = 201\n",
    "\n",
    "for step in range(TRAIN_STEPS):\n",
    "    \n",
    "    # Session will run 2 ops:\n",
    "    # summary_op prepares summary data we'll write to disk in a moment\n",
    "    # - train will use the optimzer to adjust our variables to reduce loss \n",
    "    summary_result, _ = sess.run([summary_op, train_1dLinReg])\n",
    "    \n",
    "    # write the summary data to disk\n",
    "    writer.add_summary(summary_result, step)\n",
    "    \n",
    "    # Uncomment the following 2 lines to watch training happen real-time\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run([Theta_1d,b_1d]))\n",
    "    \n",
    "# close the writer when we're finished using it \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta : 0.572324, b: -0.243654\n"
     ]
    }
   ],
   "source": [
    "print( \"Theta : %f, b: %f\" % (sess.run(Theta_1d), sess.run(b_1d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Theta_1d_out = sess.run(Theta_1d)\n",
    "print(type(Theta_1d_out))\n",
    "b_1d_out = sess.run(b_1d)\n",
    "print(type(b_1d_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.1582382187621141, 23.071660710833832)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b27684690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Xex1data1,yex1data1)\n",
    "\n",
    "# plot the line as a line connecting 2 pts., via the slope-intercept formula\n",
    "x_min,x_max = ax.get_xlim()\n",
    "y_min, y_max = b_1d_out, b_1d_out + Theta_1d_out * ( x_max-x_min)\n",
    "ax.plot([x_min,x_max], [y_min,y_max])\n",
    "ax.set_xlim([x_min,x_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_columns = [tf.feature_column.numeric_column(key=\"X\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpaHnmRn\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1b274c9950>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpaHnmRn', '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "LinRegest = tf.estimator.LinearRegressor( feature_columns=feature_columns )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# write a function to decode a line from the text file \n",
    "def decode_func_txt(line):\n",
    "    record_defaults =[[0.0],[0.0]]\n",
    "    line = tf.decode_csv(line, record_defaults=record_defaults, field_delim=',')\n",
    "    return line[:-1], line[-1] # X_i, y_i, only the last value in a line \n",
    "                            # is the output value, the prior values are input values  \n",
    "\n",
    "def create_1dimXydataset_fn(path,m_i,num_repeats=None,bool_shuffle=True,\n",
    "                            shuffle_buffer_size=10000):\n",
    "    \"\"\"\n",
    "    @fn create_1dimXydataset_fun\n",
    "    @param path, string, a string with the filename's path\n",
    "    @param m_i, a positive integer, number of examples in a batch\n",
    "    @param num_repeats, a positive integer or None, number of times to repeat, \n",
    "                        None is for indefinitely\n",
    "    @param bool_shuffle = True \n",
    "    @param shuffle_buffer_size, a positive integer, default is 10000\n",
    "    \"\"\"\n",
    "    def input_fn():\n",
    "        dataset = (\n",
    "            tf.data.TextLineDataset(path) # create a dataset from a file \n",
    "                .map(decode_func_txt, num_parallel_calls=m_i)\n",
    "                .batch(m_i)                \n",
    "        )\n",
    "        \n",
    "        if num_repeats is None:\n",
    "            dataset=dataset.repeat() # repeat indefinitely\n",
    "        else:\n",
    "            dataset=dataset.repeat(num_repeats)\n",
    "\n",
    "        if bool_shuffle:\n",
    "            dataset=dataset.shuffle(shuffle_buffer_size)    \n",
    "            \n",
    "        # create iterator\n",
    "        iterator = dataset.make_one_shot_iterator()  \n",
    "        \n",
    "        # separate the input X data from the output y data\n",
    "        X_next, y_next = iterator.get_next()\n",
    "\n",
    "        # we'll need to return the iterator as well to initialize it at tf.Session time\n",
    "        return dict(zip( [\"X\",\"y\"], [X_next, y_next]) )\n",
    "#        return iterator.get_next()\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ex1data1_fn = create_1dimXydataset_fn(sample_datasets_fileloc_str + \"/ex1data1.txt\", \n",
    "                                      128, None,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-1fd47dd3f178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLinRegest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex1data1_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    709\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step_read_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 711\u001b[0;31m             features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    712\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.pyc\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/canned/linear.pyc\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    346\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    349\u001b[0m     super(LinearRegressor, self).__init__(\n\u001b[1;32m    350\u001b[0m         \u001b[0mmodel_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/canned/linear.pyc\u001b[0m in \u001b[0;36m_linear_model_fn\u001b[0;34m(features, labels, mode, head, feature_columns, optimizer, partitioner, config)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mtrain_op_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_train_op_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         logits=logits)\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/canned/head.pyc\u001b[0m in \u001b[0;36mcreate_estimator_spec\u001b[0;34m(self, features, mode, logits, labels, train_op_fn)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;31m# Eval.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m       unweighted_loss, _ = self.create_loss(\n\u001b[0;32m--> 853\u001b[0;31m           features=features, mode=mode, logits=logits, labels=labels)\n\u001b[0m\u001b[1;32m    854\u001b[0m       \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       training_loss = losses.compute_weighted_loss(\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/estimator/canned/head.pyc\u001b[0m in \u001b[0;36mcreate_loss\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m  \u001b[0;31m# Unused for this head.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     labels = _check_labels(\n\u001b[0;32m--> 827\u001b[0;31m         _maybe_expand_dim(math_ops.to_float(labels)), self._logits_dimension)\n\u001b[0m\u001b[1;32m    828\u001b[0m     return LossAndLabels(\n\u001b[1;32m    829\u001b[0m         unweighted_loss=losses.mean_squared_error(\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mto_float\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mcannot\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcast\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m   \"\"\"\n\u001b[0;32m--> 794\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    740\u001b[0m       \u001b[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m       \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/home/mobicfd/ReacCFD/tf/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"None values not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m     \u001b[0;31m# if dtype is provided, forces numpy array to be the type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;31m# provided if possible.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "LinRegest.train( input_fn = ex1data1_fn, steps=1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named imports85",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-e51fab9718c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimports85\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named imports85"
     ]
    }
   ],
   "source": [
    "import imports85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
